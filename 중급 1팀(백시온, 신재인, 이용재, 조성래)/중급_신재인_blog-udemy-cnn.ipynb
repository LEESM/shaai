{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what we will learn ...\n",
    "\n",
    "0. what is CNN \n",
    "<hr/>\n",
    "1. Convolution Operation\n",
    "2. Relu layer\n",
    "<hr/>\n",
    "3. Pooling?\n",
    "<hr/>\n",
    "4. Flattening\n",
    "<hr/>\n",
    "5. Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is CNN \n",
    "\n",
    "![max_pool](udemy-cnn/cnn.png)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# 필요성 ::::  :::::  Image classification problem --------------------------------\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "![max_pool](udemy-cnn/ch.jpeg)\n",
    "![max_pool](udemy-cnn/ch2.jpeg)\n",
    "![max_pool](udemy-cnn/banana.jpg)\n",
    "![max_pool](udemy-cnn/ch3.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convolution Op\n",
    "\n",
    "convolution : filter 를 여러번 input_image 에 적용시켜  여러개의 feature_map 을 구하는 과정 \n",
    "\n",
    "convolution op만으로도 여러 포토샵의 효과를 만들수 있음 \n",
    "\n",
    "여러개의 feature map == convolutional layer\n",
    "\n",
    "\n",
    "![max_pool](udemy-cnn/c1.png)\n",
    "\n",
    "\n",
    "\n",
    "![max_pool](udemy-cnn/c2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Relu\n",
    "\n",
    "여러개의 feature map 으로 이루어진 convolutional layer 를 relu 에 적용시킨다. \n",
    "\n",
    "(각각의 픽셀값들이 0 이하이면 사라질 것이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Max Pooling\n",
    "\n",
    "max pooling : 하나의 feature map 을 max pool filter 통해서  pooled feature map 으로 바꾼다.  \n",
    "\n",
    "장점 : reducing size / calculation / parameters(-> prevent overfitting)\n",
    "\n",
    "이러한 장점때문에 \n",
    "\n",
    "결과적으로 cnn 에선 이런식으로 \n",
    "![max_pool](udemy-cnn/max_pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# 5. Flattening\n",
    "![max_pool](udemy-cnn/flattening2.png)\n",
    "![max_pool](udemy-cnn/flattening.png)\n",
    "\n",
    "## RESULT\n",
    "![max_pool](udemy-cnn/flattening3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Full Connection ( ANN at the tail )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![max_pool](udemy-cnn/full_connect.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![max_pool](udemy-cnn/sum.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****Loss Function 을 다양하게 사용하는 이유 \n",
    "\n",
    "## 이렇게 생긴 모델이 있다고 합시다. \n",
    "\n",
    "## 강아지와 고양이 두가지의 classification 을 수행할 수 있는 모델입니다. \n",
    "\n",
    "![max_pool](udemy-cnn/loss2.png)\n",
    "\n",
    "## 서로 구성을 조금 다르게 해서 성능이 약간 다른 두 모델의 loss 를 비교하고 싶습니다.\n",
    "\n",
    "## 각각의 모델들은 이런 결과값을 내놓았습니다. \n",
    "\n",
    "![max_pool](udemy-cnn/loss3.png)\n",
    "\n",
    "## 만약\n",
    "\n",
    "## 1. 단순히 몇개 맞추었는지 비교한다면 ? \n",
    "\n",
    "## -> 결과 동일\n",
    "\n",
    "## 2. label 과 softmax로 구한 ^ 을 제곱해서 평균 구하면 ( Mean Square )\n",
    "\n",
    "## -> 차이  조금 명확 \n",
    "\n",
    "## 3. Cross Entropy 라는 함수에 label 과 ^ 넣어서 구하면 \n",
    "\n",
    "## -> 차이 매우 명확\n",
    "\n",
    "![max_pool](udemy-cnn/loss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <<< CODE >>> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------Part 1 - Building the CNN-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Full connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',  metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------Part 2 - Fitting the CNN to the images-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "<class 'keras.preprocessing.image.DirectoryIterator'>\n",
      "Epoch 1/25\n",
      "6554/8000 [=======================>......] - ETA: 576s - loss: 0.3930 - acc: 0.8152"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "print(type(test_set))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------Part 3 - Making new predictions---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
